from flask import Flask, request, jsonify, Response, stream_with_context
from flask_cors import CORS
import requests
import json
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# APIé…ç½® - ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–APIå¯†é’¥
API_CONFIGS = {
    "tongyi": {
        "name": "é€šä¹‰åƒé—®",
        "endpoint": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "model": "qwen-plus",
        "api_key": os.getenv('TONGYI_API_KEY')
    },
    "deepseek": {
        "name": "DeepSeek",
        "endpoint": "https://api.deepseek.com/v1/chat/completions", 
        "model": "deepseek-chat",
        "api_key": os.getenv('DEEPSEEK_API_KEY')
    }
}

@app.route('/api/llm', methods=['POST'])
def proxy_llm():
    """
    ä»£ç†LLM APIè°ƒç”¨çš„æ¥å£
    æ¥æ”¶å‰ç«¯è¯·æ±‚ï¼Œè½¬å‘åˆ°å¯¹åº”çš„LLMæœåŠ¡ï¼Œå¹¶è¿”å›æµå¼å“åº”
    """
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        
        # éªŒè¯å¿…è¦å‚æ•°
        if not data:
            return jsonify({"error": "è¯·æ±‚æ•°æ®ä¸èƒ½ä¸ºç©º"}), 400
        
        api_provider = data.get('provider', 'tongyi')  # é»˜è®¤ä½¿ç”¨é€šä¹‰åƒé—®
        
        # éªŒè¯APIæä¾›å•†
        if api_provider not in API_CONFIGS:
            return jsonify({"error": f"ä¸æ”¯æŒçš„APIæä¾›å•†: {api_provider}"}), 400
        
        config = API_CONFIGS[api_provider]
        
        # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦é…ç½®
        if not config['api_key']:
            return jsonify({"error": f"{config['name']} APIå¯†é’¥æœªé…ç½®"}), 500
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        llm_request = {
            "model": config['model'],
            "messages": data.get('messages', []),
            "stream": data.get('stream', True),
            "temperature": data.get('temperature', 0.7),
            "max_tokens": data.get('max_tokens', 2000)
        }
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            "Authorization": f"Bearer {config['api_key']}",
            "Content-Type": "application/json"
        }
        
        # å¦‚æœæ˜¯æµå¼è¯·æ±‚
        if llm_request.get('stream', True):
            return stream_llm_response(config['endpoint'], llm_request, headers)
        else:
            return non_stream_llm_response(config['endpoint'], llm_request, headers)
            
    except Exception as e:
        app.logger.error(f"APIè°ƒç”¨é”™è¯¯: {str(e)}")
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500

def stream_llm_response(endpoint, request_data, headers):
    """
    å¤„ç†æµå¼å“åº”
    """
    def generate():
        try:
            response = requests.post(
                endpoint,
                json=request_data,
                headers=headers,
                stream=True,
                timeout=30
            )
            
            if response.status_code != 200:
                error_msg = f"APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                yield f"data: {json.dumps({'error': error_msg})}\n\n"
                return
            
            # é€è¡Œè¯»å–æµå¼å“åº”
            for line in response.iter_lines():
                if line:
                    line_str = line.decode('utf-8')
                    if line_str.startswith('data: '):
                        # ç›´æ¥è½¬å‘SSEæ ¼å¼çš„æ•°æ®
                        yield f"{line_str}\n\n"
                    elif line_str == 'data: [DONE]':
                        yield "data: [DONE]\n\n"
                        break
                        
        except requests.exceptions.RequestException as e:
            app.logger.error(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")
            yield f"data: {json.dumps({'error': 'ç½‘ç»œè¯·æ±‚å¤±è´¥'})}\n\n"
        except Exception as e:
            app.logger.error(f"æµå¼å“åº”å¤„ç†é”™è¯¯: {str(e)}")
            yield f"data: {json.dumps({'error': 'å“åº”å¤„ç†å¤±è´¥'})}\n\n"
    
    return Response(
        stream_with_context(generate()),
        mimetype='text/plain',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*'
        }
    )

def non_stream_llm_response(endpoint, request_data, headers):
    """
    å¤„ç†éæµå¼å“åº”
    """
    try:
        response = requests.post(
            endpoint,
            json=request_data,
            headers=headers,
            timeout=30
        )
        
        if response.status_code == 200:
            return jsonify(response.json())
        else:
            return jsonify({"error": f"APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"}), response.status_code
            
    except requests.exceptions.RequestException as e:
        app.logger.error(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")
        return jsonify({"error": "ç½‘ç»œè¯·æ±‚å¤±è´¥"}), 500
    except Exception as e:
        app.logger.error(f"å“åº”å¤„ç†é”™è¯¯: {str(e)}")
        return jsonify({"error": "å“åº”å¤„ç†å¤±è´¥"}), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    return jsonify({
        "status": "healthy",
        "message": "Flask LLMä»£ç†æœåŠ¡è¿è¡Œæ­£å¸¸",
        "supported_providers": list(API_CONFIGS.keys())
    })

@app.route('/api/providers', methods=['GET'])
def get_providers():
    """
    è·å–æ”¯æŒçš„APIæä¾›å•†åˆ—è¡¨
    """
    providers = {}
    for key, config in API_CONFIGS.items():
        providers[key] = {
            "name": config["name"],
            "model": config["model"],
            "available": bool(config["api_key"])
        }
    return jsonify(providers)

if __name__ == '__main__':
    # æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®
    print("ğŸš€ å¯åŠ¨Flask LLMä»£ç†æœåŠ¡...")
    print("ğŸ“‹ APIé…ç½®çŠ¶æ€:")
    
    for provider, config in API_CONFIGS.items():
        status = "âœ… å·²é…ç½®" if config['api_key'] else "âŒ æœªé…ç½®"
        print(f"  {config['name']} ({provider}): {status}")
    
    if not any(config['api_key'] for config in API_CONFIGS.values()):
        print("\nâš ï¸  è­¦å‘Šï¼šæ²¡æœ‰é…ç½®ä»»ä½•APIå¯†é’¥ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®ï¼š")
        print("TONGYI_API_KEY=your_tongyi_api_key")
        print("DEEPSEEK_API_KEY=your_deepseek_api_key")
    
    print(f"\nğŸŒ æœåŠ¡å°†è¿è¡Œåœ¨: http://localhost:5000")
    print("ğŸ” å¥åº·æ£€æŸ¥: http://localhost:5000/api/health")
    print("ğŸ“¡ APIæ¥å£: http://localhost:5000/api/llm")
    
    app.run(debug=True, host='0.0.0.0', port=5000) 